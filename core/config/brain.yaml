models:
  - id: "local-qwen"
    provider: "ollama"
    endpoint: "http://localhost:11434"
    name: "qwen2.5-coder:7b-instruct"
    # Auth & TLS are empty for local-dev, but structure supports expansion
    auth:
      type: "none"
    tls:
      insecure_skip_verify: true

profiles:
  # 1. The Sentry (Security - Fast & Strict)
  sentry:
    active_model: "local-qwen"
    timeout_ms: 2000
    max_retries: 0
    output_schema: "boolean"
    compression: "high"
    temperature: 0.1

  # 2. The Architect (Planning - Deep & Patient)
  architect:
    active_model: "local-qwen"
    timeout_ms: 60000
    max_retries: 2
    output_schema: "json_blueprint"
    temperature: 0.7

  # 3. The Coder (Generation - Balanced)
  coder:
    active_model: "local-qwen"
    timeout_ms: 30000
    max_retries: 3
    output_schema: "strict_json"
    temperature: 0.2

  # 4. Standard Chat (Interactive)
  chat:
    active_model: "local-qwen"
    timeout_ms: 10000
    max_retries: 1
    output_schema: ""
    temperature: 0.8
